# Exercise: sine approximation
The sine of an angle (speciﬁed in radians) can be computed by making use of the approximation sin x ≈ x if x is suﬃciently small, and the trigonometric identity:
\[
\sin x = 3\sin^3 x - 4\sin^3 x
\]

## Definitions
```scheme
(define (cube x) (* x x x))
(define (p x) (- (* 3 x) (* 4 (cube x))))
(define (sine angle)
    (if (not (> (abs angle) 0.1))
    angle
    (p (sine (/ angle 3.0)))))
```
## How many times is the procedure p applied when (sine 12.15) is evaluated?
five times:
```scheme
(sine 12.15)

(p (sine (4.05)))
(p (p (sine (1.35))))
(p (p (p (sine 0.45))))
(p (p (p (p (sine 0.15)))))
(p (p (p (p (p (sine 0.05))))))
(p (p (p (p (p 0.05)))))
```

## What is the order of growth in space and number of steps (as a function of a) used by the process generated by the sine procedure when (sine a) is evaluated?
both space and number of steps grow logarithmically with the input 

> [NOTE]  
> The following derivation was written with Copilot as I’m still not fully comfortable with LaTeX

## Derivation of Logarithmic Growth

For an arbitrary input $a$, we can derive the logarithmic dependence of time and space complexity as follows.

### Number of `p` Function Calls

The key observation is that the `sine` procedure reduces the angle by a factor of 3 on each recursive call:

$$\text{angle}_{\text{next}} = \frac{\text{angle}_{\text{current}}}{3}$$

The recursion terminates when the angle becomes sufficiently small, i.e., when:

$$|a| < 0.1 \cdot 3^n$$

where $n$ is the number of recursive calls. Rearranging this inequality:

$$3^n > \frac{|a|}{0.1}$$

Taking the logarithm (base 3) of both sides:

$$n > \log_3\left(\frac{|a|}{0.1}\right)$$

$$n > \log_3(|a|) - \log_3(0.1)$$

$$n > \log_3(|a|) + \log_3(10)$$

### Order of Growth

Since the number of recursive calls is $n \sim \Theta(\log_3(|a|))$, and each call to the `sine` procedure:
- Either returns immediately (base case), or
- Calls `p` exactly **once** before the recursive call

The number of times the `p` function is called is:

$$\boxed{T(a) = \Theta(\log(|a|))}$$

This applies to both **time complexity** and **space complexity** because:

1. **Time Complexity**: Each level of recursion performs constant work (one call to `p`), and there are $O(\log |a|)$ levels.
2. **Space Complexity**: The call stack depth is proportional to the number of recursive calls, which is $O(\log |a|)$.

Therefore, both grow **logarithmically** with respect to the input angle $a$.

